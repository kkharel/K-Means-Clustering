skew(df['Recency']**1/3) # Power transformation
skew(df['Recency']**1/10) # Power transformation
skew(df['Recency']**1/2) # Power transformation
skew(df['Recency']**0.6) # Power transformation
skew(df['Recency']**0.7) # Power transformation
skew(df['Recency']**0.55) # Power transformation
skew(df['Recency']**0.45) # Power transformation
skew(df['Recency']**0.40) # Power transformation
skew(df['Recency']**0.3) # Power transformation
skew(df['Recency']**0.35) # Power transformation
skew(df['Recency']**0.32) # Power transformation
skew(df['Recency']**0.31) # Power transformation
skew(df['Recency']**0.322) # Power transformation
skew(df['Recency']**0.321) # Power transformation
skew(df['Recency']**0.3201) # Power transformation
skew(df['Recency']**0.32001) # Power transformation
skew(df['Recency']**0.320) # Power transformation
skew(df['Recency']**0.32) # Power transformation
sns.displot(df['Recency']**0.32)
plt.show()
sns.displot(df['Recency']**0.32, kde = True)
plt.show()
from scipy.stats import anderson, shapiro, kstest
result = anderson(df['scaled_Recency']**0.32)
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = shapiro(df['scaled_Recency']**0.32)
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['scaled_Recency']**0.32, 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
from sklearn.mixture import GaussianMixture
gmm = GaussianMixture(n_components=2)  # You can adjust the number of components
gmm.fit(data.reshape(-1, 1))
thresholds = gmm.means_
gmm.fit((df['scaled_Recency']**0.32).reshape(-1, 1))
gmm.fit((df['scaled_Recency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
result = anderson(df['Recency']**0.32)
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = shapiro(df['Recency']**0.32)
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['Recency']**0.32, 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
gmm.fit((df['Recency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
gmm = GaussianMixture(n_components=1)
gmm.fit((df['Recency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
sns.displot(df['label_AboutToSleep']**0.32, kde = True)
plt.show()
sns.displot(df['Recency']**0.32, kde = True)
plt.show()
sns.displot(df['Recency']**0.32, kde = True)
plt.show()
sns.displot(df['Recency']**1/3, kde = True)
plt.show()
sns.displot(df['Recency']**(1/3), kde = True)
plt.show()
skew(df['Recency']**(0.32)(1/3)) # Power transformation
skew(df['Recency']**(1/3)) # Power transformation
skew(df['Recency']**(0.32)) # Power transformation
skew(df['Frequency'])
skew(df['Recency']**(0.33)) # Power transformation
skew(df['Recency']**(0.33.33)) # Power transformation
skew(df['Recency']**(0.3333)) # Power transformation
skew(df['Recency']**(0.32)) # Power transformation
gmm.fit((df['Recency']**(1/3)).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
gmm.fit((df['Recency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
df['Cluster'] = (df['Recency']**0.32 > thresholds).astype(int)
df['Cluster'] = (df['Recency']**0.32 > thresholds.values).astype(int)
df['Cluster'] = (df['Recency']**0.32 > thresholds).astype(int)
df['Cluster'] = ((df['Recency']**0.32) > thresholds).astype(int)
df['Cluster'] = ((df['Recency']**0.32).to_numpy() > thresholds).astype(int)
gmm = GaussianMixture(n_components=1)
gmm.fit((df['Recency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds
df['Cluster'] = ((df['Recency']**0.32) > thresholds).astype(int)
df['Cluster'] = ((df['Recency']**0.32) > thresholds[:1]).astype(int)
thresholds[1:]
thresholds[:]
thresholds[[:]]
thresholds[thresholds[:]]
thresholds[thresholds]
thresholds
thresholds.values
thresholds.values()
pd.DataFrame(thresholds)
df['Cluster'] = ((df['Recency']**0.32) > pd.DataFrame(thresholds)).astype(int)
thresholds = pd.DataFrame(thresholds)
df['Cluster'] = ((df['Recency']**0.32) > thresholds).astype(int)
df['Cluster'] = ((df['Recency']**0.32) > thresholds.squeeze()).astype(int)
thresholds.squeeze()
thresholds
thresholds = pd.DataFrame(thresholds).squeeze()
thresholds
df['Cluster'] = ((df['Recency']**0.32) > thresholds.squeeze()).astype(int)
df.head(n=2)
df.drop(columns = ['cluster'])
df.drop(columns = ['cluster'], axis = 1)
df.drop(columns = ['Cluster'], axis = 1)
df = df.drop(columns = ['Cluster'], axis = 1)
df = df.head(n=2)
df = backup
df.head(n=2)
df['label'] = df['RFM'].astype(int).apply(rfm_score_to_label)
df['label'].unique()
df = pd.get_dummies(df, columns=['label'])
df[df.columns[df.columns.str.startswith('label_')]] = df[df.columns[df.columns.str.startswith('label_')]].astype(int)
df.columns.to_list()
df.head(n=2)
df['Recency_bimodal'] = ((df['Recency']**0.32) > thresholds.squeeze()).astype(int)
df.head(n=2)
def bimodal_test(feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.05
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test('Recency')
bimodal_test('Recency')
from scipy.stats import diptest
import diptest
def bimodal_test(feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.05
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test('Recency')
bimodal_test(data = df, 'Recency')
bimodal_test(data = df, Recency)
bimodal_test(data = df, feature = Recency)
bimodal_test(data = df, feature = 'Recency')
def bimodal_test(data, feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.05
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test(data = df, feature = 'Recency')
bimodal_test(data = df, feature = 'Frequency')
bimodal_test(data = df, feature = 'scaled_Frequency')
bimodal_test(data = df, feature = 'Monetary')
bimodal_test(data = df, feature = 'Recency')
bimodal_test(data = df, feature = 'Frequency')
bimodal_test(data = df, feature = 'scaled_Frequency')
sns.displot(df['Frequency'], kde = True)
plt.show()
sns.displot(np.log(df['Frequency']), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/3), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/2), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/5), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/10), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/15), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/60), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/80), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/800), kde = True)
plt.show()
sns.displot(df['Recency']**(1/3), kde = True)
plt.show()
sns.displot(df['Frequncy']**(1/3), kde = True)
plt.show()
sns.displot(df['Frequency']**(1/3), kde = True)
plt.show()
sns.displot(np.log(df['Frequency']), kde = True)
plt.show()
df[df['Frequency'] == 1]
df[df['Frequency'] == 1].value_counts()
df[df['Frequency'] == 1].value_counts
df[df['Frequency'] == 1].value_counts.sum()
df[df['Frequency'] == 1].sum()
df[df['Frequency'] == 1].nunique()
df[df['Frequency']].nunique()
df['Frequency'].nunique()
result = anderson(df['Frequency']**0.32)
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = shapiro(df['Frequency']**0.32)
result = anderson(np.log(df['Frequency'])
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
result = anderson(np.log(df['Frequency']))
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = shapiro(np.log(df['Frequency']))
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest((np.log(df['Frequency']), 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest((np.log(df['Frequency'])), 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = shapiro(np.log(df['Frequency']))
stat, p = shapiro(df['Recency']**0.32)
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
stat, p = shapiro(np.log(df['Frequency']+1))
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
result = anderson(np.log(df['Frequency']+1))
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = kstest((np.log(df['Frequency']+1)), 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
result = anderson(np.log(df['Monetary']+1))
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = shapiro(np.log(df['Monetary']+1))
print('Shapiro-Wilk Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest((np.log(df['Monetary']+1)), 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
sns.displot(df['Recency']**(1/3), kde = True)
plt.show()
sns.displot(df['Monetary']**(1/3), kde = True)
plt.show()
sns.displot(np.log(df['Monetary']), kde = True)
plt.show()
result = anderson(df['scaled_Monetary']**0.32)
result = anderson(df['scaled_Monetary'])
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
result = shapiro(df['scaled_Monetary'])
print('Anderson-Darling Test Statistic:', result.statistic)
result = kstest(df['scaled_Monetary'])
result = kstest(df['scaled_Monetary'], 'norm')
print('Anderson-Darling Test Statistic:', result.statistic)
print('Critical Values:', result.critical_values)
stat, p = kstest(df['scaled_Frequency'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['scaled_Frequency'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['log_Frequency'], 'norm')
stat, p = kstest(df['log_F'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['Frequency'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['Monetary'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['scaled_Monetary'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
stat, p = kstest(df['log_M'], 'norm')
print('Kolmogorov-Smirnov Test Statistic:', stat)
print('p-value:', p)
sns.displot(np.log(df['Frequency']), kde = True)
plt.show()
bimodal_test(data = df, feature = 'scaled_Frequency')
bimodal_test(data = df, feature = 'scaled_Recency')
bimodal_test(data = df, feature = 'scaled_Monetary')
def bimodal_test(data, feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.10
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test(data = df, feature = 'scaled_Frequency')
bimodal_test(data = df, feature = 'scaled_Recency')
bimodal_test(data = df, feature = 'scaled_Monetary')
def bimodal_test(data, feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.02
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test(data = df, feature = 'scaled_Frequency')
bimodal_test(data = df, feature = 'scaled_Recency')
bimodal_test(data = df, feature = 'scaled_Monetary')
def bimodal_test(data, feature):
dip_statistic, p_value = diptest.diptest(data[feature])
alpha = 0.05
if p_value < alpha:
print(f"Reject the null hypothesis for {feature}: Data is not unimodal (potentially bimodal or multimodal).")
else:
print(f"Fail to reject the null hypothesis for {feature}: Data appears unimodal.")
print(f"Dip Statistic for {feature}: {dip_statistic}")
print(f"P-value for {feature}: {p_value}")
bimodal_test(data = df, feature = 'scaled_Frequency')
bimodal_test(data = df, feature = 'scaled_Recency')
bimodal_test(data = df, feature = 'scaled_Monetary')
from sklearn.mixture import GaussianMixture
gmm = GaussianMixture(n_components=1)
gmm.fit((df['scaled_Frequency']**0.32).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds = pd.DataFrame(thresholds).squeeze()
thresholds
gmm.fit((df['scaled_Frequency']).to_numpy().reshape(-1, 1))
thresholds = gmm.means_
thresholds = pd.DataFrame(thresholds).squeeze()
thresholds
df[df['Frequency']==1]
def calculate_rfm_scores(dataframe, r_col, f_col, m_col):
#dataframe.sort_values(by=[r_col, f_col, m_col], inplace=True)  # Sort the DataFrame by columns
r_quantiles = dataframe[r_col].quantile([0.2, 0.4, 0.6, 0.8])
f_quantiles = dataframe[f_col].quantile([0.2, 0.4, 0.6, 0.8])
m_quantiles = dataframe[m_col].quantile([0.2, 0.4, 0.6, 0.8])
def R_score(recency):
if recency <= r_quantiles.iloc[0]:
return 1
elif recency > r_quantiles.iloc[0] and recency <= r_quantiles.iloc[1]:
return 2
elif recency > r_quantiles.iloc[1] and recency <= r_quantiles.iloc[2]:
return 3
elif recency > r_quantiles.iloc[2] and recency <= r_quantiles.iloc[3]:
return 4
else:
return 5
def F_score(frequency):
if frequency <= f_quantiles.iloc[0]:
return 1
elif frequency > f_quantiles.iloc[0] and frequency <= f_quantiles.iloc[1]:
return 2
elif frequency > f_quantiles.iloc[1] and frequency <= f_quantiles.iloc[2]:
return 3
elif frequency > f_quantiles.iloc[2] and frequency <= f_quantiles.iloc[3]:
return 4
else:
return 5
def M_score(monetary):
if monetary <= m_quantiles.iloc[0]:
return 5
elif monetary > m_quantiles.iloc[0] and monetary <= m_quantiles.iloc[1]:
return 4
elif monetary > m_quantiles.iloc[1] and monetary <= m_quantiles.iloc[2]:
return 3
elif monetary > m_quantiles.iloc[2] and monetary <= m_quantiles.iloc[3]:
return 2
else:
return 1
dataframe['R'] = dataframe[r_col].apply(R_score)
dataframe['F'] = dataframe[f_col].apply(F_score)
dataframe['M'] = dataframe[m_col].apply(M_score)
return dataframe[['R', 'F', 'M']]
rfm_scores = calculate_rfm_scores(df, 'Recency', 'Frequency', 'Monetary')
df.head(n=2)
df[df['Frequency']==1]
def calculate_rfm_scores(dataframe, r_col, f_col, m_col):
#dataframe.sort_values(by=[r_col, f_col, m_col], inplace=True)  # Sort the DataFrame by columns
r_quantiles = dataframe[r_col].quantile([0.2, 0.4, 0.6, 0.8])
f_quantiles = dataframe[f_col].quantile([0.2, 0.4, 0.6, 0.8])
m_quantiles = dataframe[m_col].quantile([0.2, 0.4, 0.6, 0.8])
def R_score(recency):
if recency <= r_quantiles.iloc[0]:
return 1
elif recency > r_quantiles.iloc[0] and recency <= r_quantiles.iloc[1]:
return 2
elif recency > r_quantiles.iloc[1] and recency <= r_quantiles.iloc[2]:
return 3
elif recency > r_quantiles.iloc[2] and recency <= r_quantiles.iloc[3]:
return 4
else:
return 5
def F_score(frequency):
if frequency <= f_quantiles.iloc[0]:
return 5
elif frequency > f_quantiles.iloc[0] and frequency <= f_quantiles.iloc[1]:
return 4
elif frequency > f_quantiles.iloc[1] and frequency <= f_quantiles.iloc[2]:
return 3
elif frequency > f_quantiles.iloc[2] and frequency <= f_quantiles.iloc[3]:
return 2
else:
return 1
def M_score(monetary):
if monetary <= m_quantiles.iloc[0]:
return 5
elif monetary > m_quantiles.iloc[0] and monetary <= m_quantiles.iloc[1]:
return 4
elif monetary > m_quantiles.iloc[1] and monetary <= m_quantiles.iloc[2]:
return 3
elif monetary > m_quantiles.iloc[2] and monetary <= m_quantiles.iloc[3]:
return 2
else:
return 1
dataframe['R'] = dataframe[r_col].apply(R_score)
dataframe['F'] = dataframe[f_col].apply(F_score)
dataframe['M'] = dataframe[m_col].apply(M_score)
return dataframe[['R', 'F', 'M']]
rfm_scores = calculate_rfm_scores(df, 'Recency', 'Frequency', 'Monetary')
df[df['Frequency']==1]
def calculate_rfm_scores(dataframe, r_col, f_col, m_col):
#dataframe.sort_values(by=[r_col, f_col, m_col], inplace=True)  # Sort the DataFrame by columns
r_quantiles = dataframe[r_col].quantile([0.2, 0.4, 0.6, 0.8])
f_quantiles = dataframe[f_col].quantile([0.2, 0.4, 0.6, 0.8])
m_quantiles = dataframe[m_col].quantile([0.2, 0.4, 0.6, 0.8])
def R_score(recency):
if recency <= r_quantiles.iloc[0]:
return 5
elif recency > r_quantiles.iloc[0] and recency <= r_quantiles.iloc[1]:
return 4
elif recency > r_quantiles.iloc[1] and recency <= r_quantiles.iloc[2]:
return 3
elif recency > r_quantiles.iloc[2] and recency <= r_quantiles.iloc[3]:
return 2
else:
return 1
def F_score(frequency):
if frequency <= f_quantiles.iloc[0]:
return 5
elif frequency > f_quantiles.iloc[0] and frequency <= f_quantiles.iloc[1]:
return 4
elif frequency > f_quantiles.iloc[1] and frequency <= f_quantiles.iloc[2]:
return 3
elif frequency > f_quantiles.iloc[2] and frequency <= f_quantiles.iloc[3]:
return 2
else:
return 1
def M_score(monetary):
if monetary <= m_quantiles.iloc[0]:
return 5
elif monetary > m_quantiles.iloc[0] and monetary <= m_quantiles.iloc[1]:
return 4
elif monetary > m_quantiles.iloc[1] and monetary <= m_quantiles.iloc[2]:
return 3
elif monetary > m_quantiles.iloc[2] and monetary <= m_quantiles.iloc[3]:
return 2
else:
return 1
dataframe['R'] = dataframe[r_col].apply(R_score)
dataframe['F'] = dataframe[f_col].apply(F_score)
dataframe['M'] = dataframe[m_col].apply(M_score)
return dataframe[['R', 'F', 'M']]
rfm_scores = calculate_rfm_scores(df, 'Recency', 'Frequency', 'Monetary')
df[df['Frequency']==1]
def calculate_rfm_scores(dataframe, r_col, f_col, m_col):
#dataframe.sort_values(by=[r_col, f_col, m_col], inplace=True)  # Sort the DataFrame by columns
r_quantiles = dataframe[r_col].quantile([0.2, 0.4, 0.6, 0.8])
f_quantiles = dataframe[f_col].quantile([0.2, 0.4, 0.6, 0.8])
m_quantiles = dataframe[m_col].quantile([0.2, 0.4, 0.6, 0.8])
def R_score(recency):
if recency <= r_quantiles.iloc[0]:
return 1
elif recency > r_quantiles.iloc[0] and recency <= r_quantiles.iloc[1]:
return 2
elif recency > r_quantiles.iloc[1] and recency <= r_quantiles.iloc[2]:
return 3
elif recency > r_quantiles.iloc[2] and recency <= r_quantiles.iloc[3]:
return 4
else:
return 5
def F_score(frequency):
if frequency <= f_quantiles.iloc[0]:
return 5
elif frequency > f_quantiles.iloc[0] and frequency <= f_quantiles.iloc[1]:
return 4
elif frequency > f_quantiles.iloc[1] and frequency <= f_quantiles.iloc[2]:
return 3
elif frequency > f_quantiles.iloc[2] and frequency <= f_quantiles.iloc[3]:
return 2
else:
return 1
def M_score(monetary):
if monetary <= m_quantiles.iloc[0]:
return 5
elif monetary > m_quantiles.iloc[0] and monetary <= m_quantiles.iloc[1]:
return 4
elif monetary > m_quantiles.iloc[1] and monetary <= m_quantiles.iloc[2]:
return 3
elif monetary > m_quantiles.iloc[2] and monetary <= m_quantiles.iloc[3]:
return 2
else:
return 1
dataframe['R'] = dataframe[r_col].apply(R_score)
dataframe['F'] = dataframe[f_col].apply(F_score)
dataframe['M'] = dataframe[m_col].apply(M_score)
return dataframe[['R', 'F', 'M']]
rfm_scores = calculate_rfm_scores(df, 'Recency', 'Frequency', 'Monetary')
df[df['Frequency']==1]
