segment_value = 'Unknown'  # You can change this to a default value or handle it as needed
data['User'].append(user)
data['Principal Component 1'].append(user_features[0])  # Assuming principal_comp1 is the first element
data['Principal Component 2'].append(user_features[1])  # Assuming principal_comp2 is the second element
data['Cluster'].append(cluster_name)
data['Segment'].append(segment_value)
# Plot the scatter plot
fig = px.scatter(data, x='Principal Component 1', y='Principal Component 2', color='Cluster', symbol='Cluster',
title='K-Means Clustering', labels={'Principal Component 1': 'PC1', 'Principal Component 2': 'PC2'},
hover_data={'User', 'Segment'}, color_discrete_map={'Cluster': colors})
# Update marker colors
for i, color in enumerate(colors):
fig.for_each_trace(lambda t: t.update(marker=dict(color=color), selector=dict(name=f'Cluster {i}')))
# Show the plot
fig.show()
df['Cluster Label'] = -1
for ik in range(num_clusters):
df.loc[df['Customer ID'].isin(clusters[f'cluster {ik} CustomerID']), 'Cluster Label'] = ik
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
df['check_segment'] = df['RFM'].astype(int).apply(rfm_score_to_label)
import random
class Centroid:
def __init__(self, location):
self.location = location
self.closest_users = set()
def get_k_means(user_feature_map, num_features_per_user, k):
random.seed(42)
initial_centroid_users = random.sample(sorted(list(user_feature_map.keys())), k)
centroids = {f'cluster{ik}Centroids': user_feature_map[initial_centroid_users[ik]] for ik in range(k)}
for _ in range(40):
clusters = {f'cluster{ik}Users': [] for ik in range(k)}
dists = {f'centroid{ik}dists': {u: sum([abs(centroids[f'cluster{ik}Centroids'][j] - user_feature_map[u][j]) for j in range(num_features_per_user)]) for u in user_feature_map} for ik in range(k)}
for u in user_feature_map:
tempDists = [dists[f'centroid{ik}dists'][u] for ik in range(k)]
clusters[f'cluster{tempDists.index(min(tempDists))}Users'].append(u)
for ik in range(k):
sumMean = [0] * num_features_per_user
N = len(clusters[f'cluster{ik}Users'])
if N != 0:
for u in clusters[f'cluster{ik}Users']:
sumMean = [sumMean[j] + user_feature_map[u][j] / N for j in range(num_features_per_user)]
centroids[f'cluster{ik}Centroids'] = sumMean
final_clusters = {u: f'cluster{ik}Users' for ik in range(k) for u in clusters[f'cluster{ik}Users']}
return list(centroids.values()), dists, final_clusters
centroids, dists, final_clusters = get_k_means(user_feature_map=cluster_data_dict, num_features_per_user=len(list(cluster_data_dict.values())[0]), k=11)
values_list = final_clusters.get('cluster1Users', [])
num_values = len(values_list)
print("Number of values:", num_values)
print(final_clusters)
print(centroids)
import plotly.express as px
# Assuming each user has 10 features
colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange', 'purple', 'brown', 'pink']
data = {'User': [], 'Principal Component 1': [], 'Principal Component 2': [], 'Cluster': [], 'Segment': []}
for user, cluster_name in final_clusters.items():
user_features = cluster_data_dict[user]
# Assuming 'user_id' is the common column between cluster_data_dict and df
user_id = user
if user_id in df['Customer ID'].values:
segment_value = df[df['Customer ID'] == user_id]['check_segment'].iloc[0]
else:
segment_value = 'Unknown'  # You can change this to a default value or handle it as needed
data['User'].append(user)
data['Principal Component 1'].append(user_features[0])  # Assuming principal_comp1 is the first element
data['Principal Component 2'].append(user_features[1])  # Assuming principal_comp2 is the second element
data['Cluster'].append(cluster_name)
data['Segment'].append(segment_value)
# Plot the scatter plot
fig = px.scatter(data, x='Principal Component 1', y='Principal Component 2', color='Cluster', symbol='Cluster',
title='K-Means Clustering', labels={'Principal Component 1': 'PC1', 'Principal Component 2': 'PC2'},
hover_data={'User', 'Segment'}, color_discrete_map={'Cluster': colors})
# Update marker colors
for i, color in enumerate(colors):
fig.for_each_trace(lambda t: t.update(marker=dict(color=color), selector=dict(name=f'Cluster {i}')))
# Show the plot
fig.show()
df['Cluster Label'] = -1
for ik in range(num_clusters):
df.loc[df['Customer ID'].isin(clusters[f'cluster {ik} CustomerID']), 'Cluster Label'] = ik
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
import random
import copy
# set ensures that a customer can only be assigned to single Cluster
# Ordering does not matter. What matters is the above
# Set the number of clusters
num_clusters = 11
# Select random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initialize centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Get the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initialize clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculate distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assign each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Update centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Check for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Update previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
#print(f"Iteration {iteration + 1}: Clusters = {clusters}")
#print("Final Clusters:", clusters)
#print("Final Centroids:", centroids)
#print(centroids.values())
values_list = clusters.get('cluster 1 CustomerID', [])
num_values = len(values_list)
print("Number of values:", num_values)
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
def plot_clusters_2d(data_dict, centroids, clusters):
fig = go.Figure()
colormap = px.colors.qualitative.Set1
for i, centroid_key in enumerate(centroids):
if isinstance(centroids[centroid_key], list):
centroid_location = centroids[centroid_key]
else:
centroid_location = centroids[centroid_key].location
fig.add_trace(go.Scatter(x=[centroid_location[0]], y=[centroid_location[1]], mode='markers', marker=dict(size=8, color='black', symbol='x'), hoverinfo='text', text=[f'Centroid of {centroid_key}'], name=f'Centroids {i}'))
for i, cluster_key in enumerate(clusters):
cluster_points = clusters[cluster_key]
cluster_data = {k: data_dict[k] for k in cluster_points}
x = [item[0] for item in cluster_data.values()]
y = [item[1] for item in cluster_data.values()]
customer_ids = list(cluster_data.keys())
hover_text = [ f'Customer ID: {customer_id}<br>Count: {len(cluster_data)}<br>RFM: {df.loc[df["Customer ID"] == customer_id, "RFM"].values[0]}<br>Segment: {df.loc[df["Customer ID"] == customer_id, "check_segment"].values[0]}' for customer_id in customer_ids]
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', marker=dict(size=5, opacity=0.7, color=colormap[i % len(colormap)]), hoverinfo='text', text=hover_text, name=f'Cluster {i} Points'))
fig.update_layout(xaxis_title='Principal Component 0', yaxis_title='Principal Component 1', title='K-Means Clustering')
fig.show()
plot_clusters_2d(cluster_data_dict, centroids, clusters)
df['Cluster Label'] = -1
for ik in range(num_clusters):
df.loc[df['Customer ID'].isin(clusters[f'cluster {ik} CustomerID']), 'Cluster Label'] = ik
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
import random
import copy
# set ensures that a customer can only be assigned to single Cluster
# Ordering does not matter. What matters is the above
# Set the number of clusters
num_clusters = 11
# Select random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initialize centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Get the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initialize clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculate distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assign each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Update centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Check for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Update previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
#print(f"Iteration {iteration + 1}: Clusters = {clusters}")
#print("Final Clusters:", clusters)
#print("Final Centroids:", centroids)
#print(centroids.values())
values_list = clusters.get('cluster 1 CustomerID', [])
num_values = len(values_list)
print("Number of values:", num_values)
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
def plot_clusters_2d(data_dict, centroids, clusters):
fig = go.Figure()
colormap = px.colors.qualitative.Set1
for i, centroid_key in enumerate(centroids):
if isinstance(centroids[centroid_key], list):
centroid_location = centroids[centroid_key]
else:
centroid_location = centroids[centroid_key].location
fig.add_trace(go.Scatter(x=[centroid_location[0]], y=[centroid_location[1]], mode='markers', marker=dict(size=8, color='black', symbol='x'), hoverinfo='text', text=[f'Centroid of {centroid_key}'], name=f'Centroids {i}'))
for i, cluster_key in enumerate(clusters):
cluster_points = clusters[cluster_key]
cluster_data = {k: data_dict[k] for k in cluster_points}
x = [item[0] for item in cluster_data.values()]
y = [item[1] for item in cluster_data.values()]
customer_ids = list(cluster_data.keys())
hover_text = [ f'Customer ID: {customer_id}<br>Count: {len(cluster_data)}<br>RFM: {df.loc[df["Customer ID"] == customer_id, "RFM"].values[0]}<br>Segment: {df.loc[df["Customer ID"] == customer_id, "check_segment"].values[0]}' for customer_id in customer_ids]
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', marker=dict(size=5, opacity=0.7, color=colormap[i % len(colormap)]), hoverinfo='text', text=hover_text, name=f'Cluster {i} Points'))
fig.update_layout(xaxis_title='Principal Component 0', yaxis_title='Principal Component 1', title='K-Means Clustering')
fig.show()
plot_clusters_2d(cluster_data_dict, centroids, clusters)
df['Cluster Label'] = -1
for ik in range(num_clusters):
df.loc[df['Customer ID'].isin(clusters[f'cluster {ik} CustomerID']), 'Cluster Label'] = ik
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
# Setting the number of clusters
num_clusters = 11
# Selecting random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initializing centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Getting the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initializing clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculating distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assigning each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Updating centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Checking for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Updating previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
print(f"Iteration {iteration + 1}: Clusters = {clusters}")
# Setting the number of clusters
num_clusters = 11
# Selecting random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initializing centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Getting the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initializing clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculating distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assigning each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Updating centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Checking for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Updating previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
print(f"Iteration {iteration + 1}: Clusters = {clusters}")
print("Final Clusters:", clusters)
print("Final Centroids:", centroids)
print(centroids.values())
values_list = clusters.get('cluster 1 CustomerID', [])
num_values = len(values_list)
print("Number of values:", num_values)
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import random
import copy
# Setting the number of clusters
num_clusters = 11
# Selecting random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initializing centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Getting the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initializing clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculating distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assigning each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Updating centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Checking for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Updating previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
print(f"Iteration {iteration + 1}: Clusters = {clusters}")
def plot_clusters_2d(data_dict, centroids, clusters):
fig = go.Figure()
colormap = px.colors.qualitative.Set1
for i, centroid_key in enumerate(centroids):
if isinstance(centroids[centroid_key], list):
centroid_location = centroids[centroid_key]
else:
centroid_location = centroids[centroid_key].location
fig.add_trace(go.Scatter(x=[centroid_location[0]], y=[centroid_location[1]], mode='markers', marker=dict(size=8, color='black', symbol='x'), hoverinfo='text', text=[f'Centroid of {centroid_key}'], name=f'Centroids {i}'))
for i, cluster_key in enumerate(clusters):
cluster_points = clusters[cluster_key]
cluster_data = {k: data_dict[k] for k in cluster_points}
x = [item[0] for item in cluster_data.values()]
y = [item[1] for item in cluster_data.values()]
customer_ids = list(cluster_data.keys())
hover_text = [ f'Customer ID: {customer_id}<br>Count: {len(cluster_data)}<br>RFM: {df.loc[df["Customer ID"] == customer_id, "RFM"].values[0]}<br>Segment: {df.loc[df["Customer ID"] == customer_id, "check_segment"].values[0]}' for customer_id in customer_ids]
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', marker=dict(size=5, opacity=0.7, color=colormap[i % len(colormap)]), hoverinfo='text', text=hover_text, name=f'Cluster {i} Points'))
fig.update_layout(xaxis_title='Principal Component 0', yaxis_title='Principal Component 1', title='K-Means Clustering')
fig.show()
plot_clusters_2d(cluster_data_dict, centroids, clusters)
df['Cluster Label'] = -1
for ik in range(num_clusters):
df.loc[df['Customer ID'].isin(clusters[f'cluster {ik} CustomerID']), 'Cluster Label'] = ik
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
df
df['Cluster Label']
print(df.head())
result = df.groupby(['Cluster Label', 'check_segment'])['Customer ID'].count().reset_index(name='Count')
print(result)
sns.displot(df['Recency'])
plt.show()
df.head(n=2)
x = df[df['Recency'] < 320]
x['check_segment'].unique()
result[result['Cluster Label']==1]
df[df['Cluster Label'] == 1].describe()
from sklearn.metrics import silhouette_score
silhouette_avg = silhouette_score(principal_components, df['Cluster Label'])
print(f"Silhouette Score: {silhouette_avg}")
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=num_clusters, random_state=11, n_init='auto')
kmeans.fit(principal_components)
inertia = kmeans.inertia_
print(f"Inertia: {inertia}")
inertia = kmeans.inertia_
print(f"Inertia: {inertia}")
df['check_segment'] = df['RFM'].astype(int).apply(rfm_score_to_label)
# Algorithm
import random
import copy
# Setting the number of clusters
num_clusters = 11
# Selecting random initial centroids
random.seed(42)
initial_centroid_customerID = random.sample(list(cluster_data_dict.keys()), num_clusters)
# Initializing centroids
centroids = {f'cluster {ik} Centroids': cluster_data_dict[initial_centroid_customerID[ik]] for ik in range(num_clusters)}
# Getting the number of features per user
num_features_per_user = len(list(cluster_data_dict.values())[0])
# Main loop for K-means algorithm
# Maximum number of iterations
max_iterations = 20
# Previous centroids to check for convergence
prev_centroids = copy.deepcopy(centroids)
for iteration in range(max_iterations):
# Initializing clusters at the beginning of each iteration
clusters = {f'cluster {ik} CustomerID': [] for ik in range(num_clusters)}
# Calculating distances
distances = {f'centroid {ik} distance': {user: sum([(centroids[f'cluster {ik} Centroids'][feature] - cluster_data_dict[user][feature])**2 for feature in range(num_features_per_user)]) for user in cluster_data_dict} for ik in range(num_clusters)}
# Assigning each user to the nearest centroid
for user in cluster_data_dict:
temp_distance = [distances[f'centroid {ik} distance'][user] for ik in range(num_clusters)]
clusters[f'cluster {temp_distance.index(min(temp_distance))} CustomerID'].append(user)
# Updating centroids
for ik in range(num_clusters):
mean_value = [0] * num_features_per_user
cluster_size = len(clusters[f'cluster {ik} CustomerID'])
if cluster_size != 0:
for user in clusters[f'cluster {ik} CustomerID']:
mean_value = [mean_value[feature] + cluster_data_dict[user][feature] for feature in range(num_features_per_user)]
centroids[f'cluster {ik} Centroids'] = [mean_value[feature] / cluster_size for feature in range(num_features_per_user)]
else:
# If a cluster is empty, assign a random point as its centroid
centroids[f'cluster {ik} Centroids'] = cluster_data_dict[random.choice(list(cluster_data_dict.keys()))]
# Checking for convergence
if prev_centroids == centroids:
print(f"Converged at iteration {iteration + 1}")
break
# Updating previous centroids for the next iteration
prev_centroids = copy.deepcopy(centroids)
print(f"Iteration {iteration + 1}: Clusters = {clusters}")
#print("Final Clusters:", clusters)
#print("Final Centroids:", centroids)
#print(centroids.values())
values_list = clusters.get('cluster 1 CustomerID', [])
num_values = len(values_list)
print("Number of values:", num_values)
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
def plot_clusters_2d(data_dict, centroids, clusters):
fig = go.Figure()
colormap = px.colors.qualitative.Set1
for i, centroid_key in enumerate(centroids):
if isinstance(centroids[centroid_key], list):
centroid_location = centroids[centroid_key]
else:
centroid_location = centroids[centroid_key].location
fig.add_trace(go.Scatter(x=[centroid_location[0]], y=[centroid_location[1]], mode='markers', marker=dict(size=8, color='black', symbol='x'), hoverinfo='text', text=[f'Centroid of {centroid_key}'], name=f'Centroids {i}'))
for i, cluster_key in enumerate(clusters):
cluster_points = clusters[cluster_key]
cluster_data = {k: data_dict[k] for k in cluster_points}
x = [item[0] for item in cluster_data.values()]
y = [item[1] for item in cluster_data.values()]
customer_ids = list(cluster_data.keys())
hover_text = [ f'Customer ID: {customer_id}<br>Count: {len(cluster_data)}<br>RFM: {df.loc[df["Customer ID"] == customer_id, "RFM"].values[0]}<br>Segment: {df.loc[df["Customer ID"] == customer_id, "check_segment"].values[0]}' for customer_id in customer_ids]
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', marker=dict(size=5, opacity=0.7, color=colormap[i % len(colormap)]), hoverinfo='text', text=hover_text, name=f'Cluster {i} Points'))
fig.update_layout(xaxis_title='Principal Component 0', yaxis_title='Principal Component 1', title='K-Means Clustering')
fig.show()
plot_clusters_2d(cluster_data_dict, centroids, clusters)
from sklearn.metrics import silhouette_score
silhouette_avg = silhouette_score(principal_components, df['Cluster Label'])
print(f"Silhouette Score: {silhouette_avg}")
inertia = kmeans.inertia_
print(f"Inertia: {inertia}")
cluster_profiles = df.groupby('Cluster Label').mean()
print(cluster_profiles)
cluster_profiles = df.groupby('Cluster Label').mean()
df['Cluster Label'] = df['Cluster Label'].str.extract('(\d+)').astype(float)
explained_variance_ratio = pca.explained_variance_ratio_
print(f"Explained Variance Ratio: {explained_variance_ratio}")
pd.crosstab(df['Cluster Label'], df['check_segment'])
